---
title: "Cost Control"
description: "Stop runaway costs before they happen"
---

A single recursive loop can drain thousands of dollars in minutes. A hallucinating agent can spiral into an infinite retry cycle. By the time your LLM provider sends an alert, the damage is done.

Aden's cost control acts as fast as your agents think - enforcing budgets in under 100ms, before the next API call is made.

## How It Works

<CardGroup cols={2}>
  <Card title="Sub-100ms Enforcement" icon="bolt">
    Budget checks happen inline, not after the fact
  </Card>
  <Card title="Granular Budgets" icon="sliders">
    Set limits per user, agent, feature, or globally
  </Card>
</CardGroup>

## The Four Actions

When a budget threshold is hit, Aden can take one of four actions:

| Action | What Happens | When to Use |
|--------|--------------|-------------|
| **Alert** | Email notification, request continues | Early warning (80% of budget) |
| **Throttle** | Artificial delay between calls | Slow the burn rate |
| **Degrade** | Switch to a cheaper model | Preserve functionality at lower cost |
| **Block** | Request rejected immediately | Hard budget cap reached |

## Setup

Connect to the Aden control server:

```typescript
import { instrument } from "aden";
import OpenAI from "openai";

await instrument({
  apiKey: process.env.ADEN_API_KEY,
  serverUrl: process.env.ADEN_API_URL,
  sdks: { OpenAI },

  // Track usage per user for individual budgets
  getContextId: () => getCurrentUserId(),

  // Handle alerts in your app
  onAlert: (alert) => {
    console.warn(`[${alert.level}] ${alert.message}`);
  },
});
```

## Budget Hierarchy

Budgets can be set at multiple levels. More specific budgets take precedence:

```
Global Budget ($1,000/month)
    └── Feature Budget: "customer-support" ($500/month)
            └── Agent Budget: "support-agent-v2" ($100/month)
                    └── User Budget: "user_123" ($10/month)
```

A $10 user budget will block that user even if the global budget has room. This transforms your LLM bill from a single number into a granular balance sheet.

## Setting Budgets

### Per-User Budget

```bash
curl -X POST https://api.adenhq.com/v1/budgets \
  -H "Authorization: Bearer $ADEN_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "context_id": "user_123",
    "limit_usd": 10.00,
    "period": "monthly",
    "actions": {
      "80": "alert",
      "100": "block"
    }
  }'
```

### Global Budget

```bash
curl -X POST https://api.adenhq.com/v1/budgets \
  -H "Authorization: Bearer $ADEN_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "limit_usd": 1000.00,
    "period": "monthly",
    "actions": {
      "80": "alert",
      "100": "degrade"
    }
  }'
```

## Model Degradation

Automatically switch to cheaper models when approaching budget limits:

```bash
curl -X POST https://api.adenhq.com/v1/degradation-rules \
  -H "Authorization: Bearer $ADEN_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "from_model": "gpt-4o",
    "to_model": "gpt-4o-mini",
    "trigger_percent": 80
  }'
```

When any budget reaches 80%, `gpt-4o` requests are automatically served with `gpt-4o-mini`. The request succeeds, your users stay unblocked, and you save ~95% on that call.

## Handling Actions in Your Code

### Blocked Requests

When a request is blocked, a `RequestCancelledError` is thrown:

```typescript
import { RequestCancelledError } from "aden";

try {
  await openai.chat.completions.create({
    model: "gpt-4o",
    messages: [{ role: "user", content: "Hello" }],
  });
} catch (error) {
  if (error instanceof RequestCancelledError) {
    // Show user-friendly message
    return "You've reached your usage limit for this month.";
  }
  throw error;
}
```

### Degraded Requests

Degraded requests proceed normally with the cheaper model:

```typescript
const response = await openai.chat.completions.create({
  model: "gpt-4o", // Requested
  messages: [{ role: "user", content: "Hello" }],
});

console.log(response.model); // "gpt-4o-mini" if degraded
```

### Alert Callbacks

Route alerts to your notification systems:

```typescript
await instrument({
  onAlert: async (alert) => {
    switch (alert.level) {
      case "critical":
        await pagerduty.trigger(alert.message);
        break;
      case "warning":
        await slack.postMessage("#llm-alerts", alert.message);
        break;
    }
  },
});
```

## Reliability

Aden is designed to never break your agents:

- **Fail-open by default**: If the control server is unreachable, requests proceed
- **Graceful completion**: Mid-response requests complete before blocking takes effect
- **Overage tolerance**: Less than 5% overage allowed to avoid cutting off critical operations

Configure fail behavior:

```typescript
await instrument({
  apiKey: process.env.ADEN_API_KEY,
  failOpen: true, // Default: allow requests if server unreachable
});
```

## Local Development

For testing without a server connection, use `beforeRequest` to mock budget logic:

```typescript
await instrument({
  sdks: { OpenAI },
  beforeRequest: async (request) => {
    // Your local budget logic here
    return { action: "proceed" };
  },
});
```

## Next Steps

<CardGroup cols={2}>
  <Card title="Agent Tracking" icon="robot" href="/sdk/typescript/agent-tracking">
    Track multi-agent workflows with traces and spans
  </Card>
  <Card title="Emitters" icon="tower-broadcast" href="/sdk/typescript/emitters">
    Send metrics to your observability stack
  </Card>
</CardGroup>
